{"url": "https://en.wikipedia.org/wiki/Mistral_AI", "title": null, "text": "French artificial intelligence company.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme) div:not(.notheme){background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table tr{display:table-row!important}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}.mw-parser-output .ib-company .infobox-label{padding-right:0.5em}.mw-parser-output .ib-company .infobox-data,.mw-parser-output .ib-company .infobox-below{line-height:1.35em}.mw-parser-output .ib-company-logo img{background-color:#f8f9fa}.mw-parser-output .ib-company-locality,.mw-parser-output .ib-company-country{display:inline}Mistral AI SASCompany typePrivateIndustryArtificial intelligenceFounded28 April 2023; 23 months ago\u00a0(28 April 2023)Founders.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Arthur MenschGuillaume LampleTimoth\u00e9e LacroixHeadquartersParis, FranceKey peopleArthur Mensch (CEO)Guillaume Lample (Chief Scientist)Timoth\u00e9e Lacroix (CTO)ProductsMistral 7BMixtral 8x7BMistral MediumMistral LargeMistral Large 2 (123B)Mixtral 8x22BCodestral 22BCodestral Mamba (7B)Mathstral (7B)Mistral NeMo 12BMistral EmbedMistral Small 3.1Number of employees150 (2025)[1]Websitemistral.ai.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onArtificial intelligence (AI)Major goalsArtificial general intelligenceIntelligent agentRecursive self-improvementPlanningComputer visionGeneral game playingKnowledge reasoningNatural language processingRoboticsAI safetyApproachesMachine learningSymbolicDeep learningBayesian networksEvolutionary algorithmsHybrid intelligent systemsSystems integrationApplicationsBioinformaticsDeepfakeEarth sciences Finance Generative AIArtAudioMusicGovernmentHealthcareMental healthIndustryTranslation Military PhysicsProjectsPhilosophyArtificial consciousnessChinese roomFriendly AIControl problem/TakeoverEthicsExistential riskTuring testUncanny valleyHistoryTimelineProgressAI winterAI boomGlossaryGlossary.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteMistral AI SAS is a French artificial intelligence (AI) startup, headquartered in Paris. It specializes in open-weight large language models (LLMs).[2][3]Namesake[edit]The company is named after the mistral, a powerful, cold wind in southern France.[4]History[edit]Mistral AI was established in April 2023 by three French AI researchers, Arthur Mensch, Guillaume Lample and Timoth\u00e9e Lacroix.[5]Mensch, an expert in advanced AI systems, is a former employee of Google DeepMind; Lample and Lacroix, meanwhile, are large-scale AI models specialists who had worked for Meta Platforms.[6]The trio originally met during their studies at \u00c9cole Polytechnique.[4]Example of an image generated with Le Chat, the prompt is Generate an image you feel represents yourself, Mistral AIScreenshot of Le Chat, Mistral AI chatbot, describing Wikipedia in a thoughtful wayCompany operation[edit]Philosophy[edit]Mistral AI emphasizes openness and innovation in the AI field and positions itself as an alternative to proprietary models.[7]The company has gained prominence as an alternative to proprietary AI systems as it aims to \"democratize\" AI by focusing on open-source innovation.[8]Funding[edit]In June 2023, the start-up carried out a first fundraising of \u20ac105 million ($117 million) with investors including the American fund Lightspeed Venture Partners, Eric Schmidt, Xavier Niel and JCDecaux. The valuation is then estimated by the Financial Times at \u20ac240 million ($267 million).\nOn 10 December 2023, Mistral AI announced that it had raised \u20ac385 million ($428 million) as part of its second fundraising. This round of financing involves the Californian fund Andreessen Horowitz, BNP Paribas and the software publisher Salesforce.[9]In October 2023, Mistral AI raised \u20ac385 million.[10]By December 2023, it was valued at over $2 billion.[11][12][13]On 16 April 2024, reporting revealed that Mistral was in talks to raise \u20ac500 million, a deal that would more than double its current valuation to at least \u20ac5 billion.[14]In June 2024, Mistral AI secured a \u20ac600 million ($645 million) funding round, elevating its valuation to \u20ac5.8 billion ($6.2 billion).[15]Led by venture capital firm General Catalyst,[16] this round resulted in additional contributions from existing investors. The funds aim to support the company's expansion.\nBased on valuation, the company is currently in fourth place in the global AI race and in first place outside the San Francisco Bay Area, ahead of several of its peers, such as Cohere, Hugging Face, Inflection and Perplexity.[17]Partnership with Microsoft[edit]On 26 February 2024, Microsoft announced a new partnership with the company to expand its presence in the artificial intelligence industry.\nUnder the agreement, Mistral's language models will be available on Microsoft's Azure cloud, while the multilingual conversational assistant Le Chat will be launched in the style of ChatGPT.[18]Services[edit]Le Chat[edit]On November 19, 2024, the company announced updates for Le Chat (pronounced \\l\u0259 t\u0283at\\ in french).\nIt added the ability to create images, in partnership with Black Forest Labs, utilizing the Flux Pro model.\nAdditionally, it introduced the capability to search for information on the internet to provide reliable and up-to-date information.\nFurthermore, it launched the Canvas system, a collaborative interface where the AI generates code and the user can modify it.\nMobile app[edit]On February 6, 2025, Mistral AI released its AI assistant, Le Chat, on iOS and Android, making its language models accessible on mobile devices.\nLe Chat offers features including web search, image generation, and real-time updates.\nMistral AI also introduced a Pro subscription tier, priced at $14.99 per month, which provides access to more advanced models, unlimited messaging, and web browsing.[19]Models[edit]The following table lists the main model versions of Mistral, describing the significant changes included with each version:[20]\n\nNameRelease DateStatusNumber of Parameters (Billion)LicenseNotes\nMistral Small 3.1 25.03March 2025Active\n24\nApache-2.0A new leader in the small models category with image understanding capabilities, with the lastest version v3.1 released March 2025.[21][22]Mistral Small 3 25.01January 2025?\n24\nApache-2.0Upon its release in January 2025, Mistral Small 3 is benchmarked as the leader in the \"small\" models category below 70B, featuring 24B parameters and capabilities comparable to those of larger models.[23][21]Mistral Large 2 24.11November 2024Active\n123\nMistral Research License\n[21]Pixtral Large 24.11November 2024?\n124\nMistral Research License\nOn November 19, 2024, the company introduced Pixtral Large, an improvement over Pixtral 12B, integrating a 1-billion-parameter visual encoder coupled with Mistral Large 2. This model has also been enhanced, particularly for long contexts and function calls.[24][21]Ministral 8B 24.10October 2024?\n8\nMistral Research License\n[21]Ministral 3B 24.10October 2024?\n3\nProprietary[21]Pixtral 24.09September 2024?\n12\nApache-2.0[21]Mistral Large 2 24.07July 2024?\n123\nMistral Research License\nMistral Large 2 was announced on July 24, 2024, and released on Hugging Face. It is available for free with a Mistral Research Licence, and with a commercial licence for commercial purposes. Mistral AI claims that it is fluent in dozens of languages, including many programming languages. Unlike the previous Mistral Large, this version was released with open weights. The model has 123 billion parameters and a context length of 128,000 tokens.[21]Codestral Mamba 7B\nJuly 2024?\n7\nApache-2.0Codestral Mamba is based on the Mamba 2 architecture, which allows it to generate responses even with longer input.[25] Unlike Codestral, it was released under the Apache 2.0 license. While previous releases often included both the base model and the instruct version, only the instruct version of Codestral Mamba was released.[26][21]Mathstral 7B\nJuly 2024?\n7\nApache-2.0Mathstral 7B is a model with 7 billion parameters released by Mistral AI on July 16, 2024, focusing on STEM subjects.[27] The model was produced in collaboration with Project Numina,[25] and was released under the Apache 2.0 License with a context length of 32k tokens.[27][21]Codestral 22B\nMay 2024?\n22\nMistral Non-Production License\nCodestral is Mistral's first code-focused open weight model which was launched on May 29, 2024. Mistral claims Codestral is fluent in more than 80 programming languages[28] Codestral has its own license which forbids the usage of Codestral for commercial purposes.[29][21]Mixtral 8x22B\nApril 2024?\n22\nApache-2.0Similar to Mistral's previous open models, Mixtral 8x22B was released via a BitTorrent link on Twitter on April 10, 2024,[30] with a release on Hugging Face soon after.[31] The model uses an architecture similar to that of Mistral 8x7B, but with each expert having 22 billion parameters instead of 7. In total, the model contains 141 billion parameters, as some parameters are shared among the experts, but offering higher performance.[31][32][21]Mistral Small\nFebruary 2024?\n?\nProprietaryLike the Large model, Mistral Small was launched on February 26, 2024.[21]Mistral Large 24.02February 2024?\n?\nProprietaryMistral Large was launched on February 26, 2024, and Mistral claims it is second in the world only to OpenAI's GPT-4. It is fluent in English, French, Spanish, German, and Italian, with Mistral claiming understanding of both grammar and cultural context, and provides coding capabilities. As of early 2024, it is Mistral's flagship AI.[33] It is also available on Microsoft Azure.[34][21]Mistral Medium\nDecember 2023?\n?\nProprietaryMistral Medium is trained in various languages including English, French, Italian, German, Spanish and code with a score of 8.6 on MT-Bench.[35] It is ranked in performance above Claude and below GPT-4 on the LMSys ELO Arena benchmark.[36] The number of parameters, and architecture of Mistral Medium is not known as Mistral has not published public information about it.[21]Mixtral 8x7B\nDecember 2023?\n46.7\nApache-2.0Much like Mistral's first model, Mixtral 8x7B was released via a BitTorrent link posted on Twitter on December 9, 2023,[2] and later Hugging Face and a blog post were released two days later.[37] Unlike the previous Mistral model, Mixtral 8x7B uses a sparse mixture of experts architecture. The model has 8 distinct groups of \"experts\", giving the model a total of 46.7B usable parameters.[38][39] Each single token can only use 12.9B parameters, therefore giving the speed and cost that a 12.9B parameter model would incur.[37] A version trained to follow instructions called \u201cMixtral 8x7B Instruct\u201d is also offered.[37][21]Mistral 7B\nSeptember 2023?\n7.3\nApache-2.0Mistral 7B is a 7.3B parameter language model using the transformers architecture. It was officially released on September 27, 2023, via a BitTorrent magnet link,[40] and Hugging Face[41] under the Apache 2.0 license. Mistral 7B employs grouped-query attention (GQA), which is a variant of the standard attention mechanism. This architecture optimizes performance by calculating attention within specific groups of hidden states rather than across all hidden states, improving efficiency and scalability.[42] Both a base model and \"instruct\" model were released with the latter receiving additional tuning to follow chat-style prompts. The fine-tuned model is only intended for demonstration purposes, and does not have guardrails or moderation built-in.[43][21]Performance[edit]Mistral 7B[edit]Mistral AI claimed in the Mistral 7B release blog post that the model outperforms LLaMA 2 13B on all benchmarks tested, and is on par with LLaMA 34B on many benchmarks tested,[43] despite having only 7 billion parameters, a small size compared to its competitors.\nMixtral 8x7B[edit]Mistral AI's testing in 2023 shows the model beats both LLaMA 70B, and GPT-3.5 in most benchmarks.[44]In March 2024, a research conducted by Patronus AI comparing performance of LLMs on a 100-question test with prompts to generate text from books protected under U.S. copyright law found that Open AI's GPT-4, Mixtral, Meta AI's LLaMA-2, and Anthropic's Claude 2 generated copyrighted text verbatim in 44%, 22%, 10%, and 8% of responses respectively.[45][46]Mistral Large 2[edit]According to Mistral AI, Large 2's performance in benchmarks is competitive with Llama 3.1 405B, particularly in programming-related tasks.[47][48]Codestral 22B[edit]As of its release date, Codestral 22B surpasses Meta's Llama3 70B and DeepSeek Coder 33B (78.2% - 91.6%), another code-focused model on the HumanEval FIM benchmark.[49]Mathstral 7B[edit]Mathstral 7B achieved a score of 56.6% on the MATH benchmark and 63.47% on the MMLU benchmark.[27]Mistral Small 3.1[edit]On 17 March 2025, Mistral released Mistral Small 3.1 under the Apache 2.0 license as a smaller, more efficient model.[50]Usage[edit]According to Mistral AI,[51] the company's products have been used by\u00a0:\nBNP ParibasAXALaboratoires Pierre FabreCMA CGMZalandoMiraklFrance TravailReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Bradshaw, Tim; Abboud, Leila (30 January 2025). \"Has Europe's great hope for AI missed its moment?\". Financial Times.^ ab\"Buzzy Startup Just Dumps AI Model That Beats GPT-3.5 Into a Torrent Link\". Gizmodo. 12 December 2023. Retrieved 16 December 2023.^\"What is Mistral AI?\". IBM. October 2024.^ abJournal, Sam Schechner | Photographs by Edouard Jacquinet for The Wall Street. \"The 9-Month-Old AI Startup Challenging Silicon Valley's Giants\". WSJ. Retrieved 31 March 2024.^\"Spotlight Interview: Mistral AI CEO Arthur Mensch\". The French Tech Journal. 24 June 2024.^\"France's unicorn start-up Mistral AI embodies its artificial intelligence hopes\". Le Monde.fr. 12 December 2023.^\"Bringing open AI models to the frontier\". Mistral AI. 27 September 2023. Retrieved 4 January 2024.^Webb, Maria (2 January 2024). \"Mistral AI: Exploring Europe's Latest Tech Unicorn\". techopedia.com. Retrieved 13 June 2024.^\"Mistral l\u00e8ve 385 M\u20ac et devient une licorne fran\u00e7aise - le Monde Informatique\". 11 December 2023.^Metz, Cade (10 December 2023). \"Mistral, French A.I. Start-Up, Is Valued at $2 Billion in Funding Round\". The New York Times.^Fink, Charlie. \"This Week In XR: Epic Triumphs Over Google, Mistral AI Raises $415 Million, $56.5 Million For Essential AI\". Forbes. Retrieved 16 December 2023.^\"A French AI start-up may have commenced an AI revolution, silently\". Hindustan Times. 12 December 2023.^Abboud, Leila; Levingston, Ivan; Hammond, George (8 December 2023). \"French AI start-up Mistral secures \u20ac2bn valuation\". Financial Times. ft.com Financial Times.^Abboud, Leila; Levingston, Ivan; Hammond, George (19 April 2024). \"Mistral in talks to raise \u20ac500mn at \u20ac5bn valuation\". Financial Times. Retrieved 19 April 2024.^Kharpal, Arjun (24 May 2024). \"CEOs of AI startups backed by Microsoft and Amazon are the new tech rockstars\". CNBC. Retrieved 13 June 2024.^\"Tripling Down on Mistral AI | General Catalyst\". www.generalcatalyst.com. Retrieved 13 June 2024.^Bratton, Laura (12 June 2024). \"OpenAI's French rival Mistral AI is now worth $6 billion. That's still a fraction of its top competitors\". Quartz (publication). Retrieved 13 June 2024.^Bableshwar (26 February 2024). \"Mistral Large, Mistral AI's flagship LLM, debuts on Azure AI Models-as-a-Service\". techcommunity.microsoft.com. Retrieved 26 February 2024.^\"Mistral releases its genAI assistant Le Chat for IOS and Android\". Computerworld. 7 February 2025. Retrieved 7 February 2025.^\"Models Overview\". mistral.ai. Archived from the original on 9 April 2025. Retrieved 20 April 2025.^ abcdefghijklmnopq\"Models Overview\". mistral.ai. Retrieved 3 March 2025.^\"Mistral Small 3.1 | Mistral AI\". mistral.ai. Retrieved 24 March 2025.^https://ollama.com/library/mistral-small:24b^\"Mistral has entered the chat\". Mistral AI. 18 November 2024. Retrieved 11 December 2024.^ abDavid, Emilia (16 July 2024). \"Mistral releases Codestral Mamba for faster, longer code generation\". VentureBeat. Retrieved 17 July 2024.^AI, Mistral (16 July 2024). \"Codestral Mamba\". mistral.ai. Retrieved 16 July 2024.^ abcAI, Mistral (16 July 2024). \"Math\u03a3tral\". mistral.ai. Retrieved 16 July 2024.^Sharma, Shubham (29 May 2024). \"Mistral announces Codestral, its first programming focused AI model\". VentureBeat. Retrieved 30 May 2024.^Wiggers, Kyle (29 May 2024). \"Mistral releases Codestral, its first generative AI model for code\". TechCrunch. Retrieved 30 May 2024.^@MistralAI (10 April 2024). \"Torrent\" (Tweet) \u2013 via Twitter.^ ab\"mistralai/Mixtral-8x22B-v0.1 \u00b7 Hugging Face\". huggingface.co. Retrieved 5 May 2024.^\"Mistral Releases Latest Open Source Model, Mixtral 8x22B\". Pure AI. 17 April 2024.^AI, Mistral (26 February 2024). \"Au Large\". mistral.ai. Retrieved 6 March 2024.^Boyd, Eric (26 February 2024). \"Introducing Mistral-Large on Azure in partnership with Mistral AI\". Microsoft Azure Blog. Retrieved 17 February 2025.^AI, Mistral (11 December 2023). \"La plateforme\". mistral.ai. Retrieved 22 January 2024.^\"LMSys Chatbot Arena Leaderboard - a Hugging Face Space by lmsys\". huggingface.co. Retrieved 22 January 2024.^ abc\"Mixtral of experts\". mistral.ai. 11 December 2023. Retrieved 4 January 2024.^\"Mixture of Experts Explained\". huggingface.co. Retrieved 4 January 2024.^Marie, Benjamin (15 December 2023). \"Mixtral-8x7B: Understanding and Running the Sparse Mixture of Experts\". Medium. Retrieved 4 January 2024.^Goldman, Sharon (8 December 2023). \"Mistral AI bucks release trend by dropping torrent link to new open source LLM\". VentureBeat. Retrieved 4 January 2024.^Coldewey, Devin (27 September 2023). \"Mistral AI makes its first large language model free for everyone\". TechCrunch. Retrieved 4 January 2024.^Jiang, Albert Q.; Sablayrolles, Alexandre; Mensch, Arthur; Bamford, Chris; Chaplot, Devendra Singh; Casas, Diego de las; Bressand, Florian; Lengyel, Gianna; Lample, Guillaume (10 October 2023). \"Mistral 7B\". arXiv:2310.06825v1 [cs.CL].^ ab\"Mistral 7B\". mistral.ai. Mistral AI. 27 September 2023. Retrieved 4 January 2024.^Franzen, Carl (11 December 2023). \"Mistral shocks AI community as latest open source model eclipses GPT-3.5 performance\". VentureBeat. Retrieved 4 January 2024.^Field, Hayden (6 March 2024). \"Researchers tested leading AI models for copyright infringement using popular books, and GPT-4 performed worst\". CNBC. Retrieved 6 March 2024.^\"Introducing CopyrightCatcher, the first Copyright Detection API for LLMs\". Patronus AI. 6 March 2024. Retrieved 6 March 2024.^AI, Mistral (24 July 2024). \"Large Enough\". mistral.ai. Retrieved 24 July 2024.^\"mistralai/Mistral-Large-Instruct-2407 \u00b7 Hugging Face\". huggingface.co. Retrieved 24 August 2024.^AI, Mistral (29 May 2024). \"Codestral: Hello, World!\". mistral.ai. Retrieved 30 May 2024.^\"Mistral Small 3.1 | Mistral AI\". mistral.ai. Retrieved 24 March 2025.^\"Solutions - for any use case | Mistral AI\". mistral.ai. Retrieved 17 February 2025.External links[edit]Official website.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteGenerative AIchatbotsLarge language modelChatGPTCharacter.aiClaudeDeepSeekERNIEGeminiGrokManusCopilotMinervaMistralPerplexity AIQwenReplikaVelvetYandexGPTYou.comCategoryvteGenerative AIConceptsAutoencoderDeep learningGenerative adversarial networkGenerative pre-trained transformerLarge language modelNeural networkPrompt engineeringRetrieval-augmented generationReinforcement learning from human feedbackSelf-supervised learningTransformerVariational autoencoderVision transformerWord embeddingModelsTextClaudeDBRXDeepSeekERNIEGeminiGPT123JChatGPT44oo1o34.54.1o4GrokGraniteLlamaManusMistral LargePanGu-\u03a3QwenImageAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyStable DiffusionSpeech15.aiWaveNetVideoDream MachineGen-4Hailuo AIKlingSoraVeoVideoPoetMusicEndelUdioSuno AICompanies01.AIAlibabaAnthropicBaichuanBaiduDeepSeekElevenLabsGoogle DeepMindHugging FaceKuaishouMeta AIMiniMaxMistral AIMoonshot AIOpenAIRunwayStability AISynthesiaxAIZhipu AICategoryCommons\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Mistral_AI&oldid=1286980124\"", "tags": ["en.wikipedia.org", "wiki", "mistral", "ai"]}
{"url": "https://en.wikipedia.org/wiki/Cohere", "title": null, "text": "Canadian natural language processing startup.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}For other uses, see Coherence (disambiguation)..mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme) div:not(.notheme){background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table tr{display:table-row!important}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}.mw-parser-output .ib-company .infobox-label{padding-right:0.5em}.mw-parser-output .ib-company .infobox-data,.mw-parser-output .ib-company .infobox-below{line-height:1.35em}.mw-parser-output .ib-company-logo img{background-color:#f8f9fa}.mw-parser-output .ib-company-locality,.mw-parser-output .ib-company-country{display:inline}Cohere Inc.Company typePrivateIndustry.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Natural language processingArtificial intelligenceFounded2019; 6\u00a0years ago\u00a0(2019)FoundersAidan Gomez, Ivan Zhang, Nick FrosstHeadquartersToronto, OntarioSan Francisco, CaliforniaKey peopleAidan Gomez (CEO)Martin Kon (president & COO)Jaron Waldman (CPO)Number of employees300 (2024)[1]Websitecohere.comCohere Inc. is a Canadian multinationaltechnology company focused on artificial intelligence for the enterprise, specializing in large language models.[2] Cohere was founded in 2019 by Aidan Gomez, Ivan Zhang, and Nick Frosst,[3] and is headquartered in Toronto and San Francisco, with offices in Palo Alto, London, and New York City.[4][5][6]History[edit]In 2017, a team of researchers at Google Brain introduced the transformer machine learning architecture in \"Attention Is All You Need,\" which demonstrated state-of-the-art performance on a variety of natural language processing tasks.[7][8] In 2019, Aidan Gomez, one of its co-authors, along with Nick Frosst, another researcher at Google Brain, founded Cohere with Ivan Zhang, with whom Gomez had done research at FOR.ai.[9][10] All of the co-founders attended University of Toronto.[11] \nGomez is the company's CEO.[10] In December 2022, Martin Kon, the former CFO of YouTube, became president and COO.[12]In November 2021, Google Cloud announced that they would help power Cohere's platform using their robust infrastructure, and Cloud's TPUs would be used by Cohere for the development and deployment of their products.[13][14]In June 2022, Cohere launched Cohere For AI, a nonprofit research lab and community dedicated to contributing open-source, fundamental machine learning research. It is led by Sara Hooker, a former research scientist at Google Brain.[15]In December 2022, Cohere released a multilingual model for understanding text that would work with over 100 languages, to help users search for documents by meaning instead of with keywords. This type of process was not previously widely available in languages other than English.[12]On June 13, 2023, Oracle announced a partnership with Cohere to provide generative AI services to help organizations automate end-to-end business processes. As a result, Cohere's technology is integrated into Oracle's business applications, including Oracle Fusion Cloud, Oracle NetSuite, and Oracle industry-specific applications.[16] On July 18, 2023, McKinsey announced a collaboration with Cohere, to help organizations integrate generative AI into their operations.[17] In 2023, Cohere collaborated with software company LivePerson to offer customized large language models for businesses.[2]On September 12, 2023, it was announced that Cohere had become one of 15 tech companies to agree to voluntary White House measures on testing, reporting, and research on the risks of AI.[18] On September 27, 2023, it was announced that Cohere had also signed Canada's voluntary code of conduct for AI, to promote the responsible development and management of advanced generative AI systems.[19]Products[edit]Considered an alternative to OpenAI,[20] Cohere is focused on generative AI for the enterprise, building technology that businesses can use to deploy chatbots, search engines, copywriting, summarization, and other AI-driven products.[2][21] Cohere specializes in large language models: AI trained to digest text from an enterprises' internal data or publicly available sources like the internet to understand how to process and respond to prompts with increasing sophistication.[12]The Cohere platform is available through API as a managed service, through platforms such as Amazon SageMaker and Google's Vertex AI. It can be used for tasks such as writing copy, moderating content, classifying data, and extracting information. It is cloud agnostic and not tied to a particular cloud service.[10]Cohere's generative AI technology is embedded into several Oracle products, and its chat capabilities are embedded into Salesforce products.[20]Launched in January 2025 in partnership with RBC, North for Banking is a secure generative AI platform designed to enhance productivity and data security in financial services.[22]In March of 2025, Cohere's nonprofit research lab introduced Aya Vision, an AI model that can describe images, translate text, and summarize information. The model is free to use for research but is not permitted to be used for commercial purposes.[23]Funding[edit]On September 7, 2021, Cohere announced that they had raised $40 million in Series A funding led by Index Ventures; Index Ventures partner Mike Volpi also joined Cohere's board.[13][14] The round also included Radical Ventures, Section 32, and AI-experts Geoffrey Hinton, Fei-Fei Li, Pieter Abbeel, and Raquel Urtasun.[3]In February 2022, Cohere announced they had raised $125 million in series B funding led by Tiger Global.[24] In June 2023, Cohere raised an additional $270 million in series C funding from investors including Inovia Capital, Oracle, Salesforce, and Nvidia, at a valuation of $2.2 billion.[2][25]  \nIn March 2024, it was reported that Cohere had an annualized revenue run rate of $22 million and in July 2024 it was reported they closed $500 million in funding from investors including Cisco, AMD and Fujitsu at a valuation of $5.5 billion.[26][27]In December 2024, Cohere received $240 million in public funding from the Canadian government as part of the Canadian Sovereign AI Compute Strategy to support the construction of a domestic AI data center.[28]Litigation[edit]In February 2025, it was reported that a consortium of 14 publishing companies including The Atlantic, Cond\u00e9 Nast, and Forbes had sued Cohere for copyright infringement, accusing Cohere of using their content for training without permission, as well as displaying considerable portions or entire articles of their content without permission.[29]See also[edit]BabelnetDeeplvidbyOpenAIReferences[edit]^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Bratton, Laura (March 1, 2024). \"Canada's leading AI startup is taking its talents to New York\". Quartz.^ abcdGoldberg, Natalie (8 June 2023). \"Nvidia invests in Google-linked generative A.I. startup Cohere\". CNBC. Retrieved 6 October 2023.^ abSilcoff, Sean (2021-09-07). \"Toronto AI startup Cohere raises US$40-million as it looks to bring Google-quality predictive language to masses\". The Globe and Mail. Retrieved 2021-12-31.^Hu, Krystal (March 1, 2024). \"\"AI startup Cohere opens New York office in expansion\"\". Reuters. Archived from the original on May 14, 2024. Retrieved May 26, 2024.^Rai, Saritha (13 September 2023). \"AI Startup Cohere Opens Second Headquarters in San Francisco\". Bloomberg. Retrieved 3 October 2023.^\"Cohere\". read.cv. Archived from the original on 2023-07-17. Retrieved 2023-07-17.^\"Cohere raises $40 million USD to make natural language processing more accessible | BetaKit\". 2021-09-08. Retrieved 2021-12-31.^Sullivan, Mark (2021-09-07). \"Ex-Googlers raise $40 million to democratize natural-language AI\". Fast Company. Retrieved 2021-12-31.^\"Cracking the code: This group of U of T computer science researchers are decoding ciphers with AI\". University of Toronto News. Retrieved 2021-12-31.^ abcGoldman, Sharon (9 February 2023). \"OpenAI rival Cohere AI has flown under the radar. That may be about to change\". Venture Beat. Retrieved 3 October 2023.^\"AI startup Cohere raises US$40-million for natural language software: Globe and Mail\". University of Toronto News. Retrieved 2021-12-31.^ abcO'Kane, Josh (14 December 2022). \"Rising AI startup Cohere hires YouTube CFO Martin Kon as president\". The Globe and Mail. Retrieved 3 October 2023.^ ab\"Google Cloud teams up with NLP startup Cohere on multiyear partnership around TPUs\". TechCrunch. 17 November 2021. Retrieved 2021-12-31.^ abCohere (2021-09-07). \"Cohere Raises $40 Million in Series A Financing to Make Natural Language Processing Safe and Accessible to Any Business\". GlobeNewswire News Room (Press release). Retrieved 2021-12-31.^Goldman, Sharon (14 June 2022). \"Google Brain alum to helm new nonprofit AI research lab\". Venture Beat. Retrieved 9 October 2023.^Ajao, Esther (13 June 2023). \"Oracle plans to provide generative AI services with Cohere\". Tech Target. Retrieved 9 October 2023.^Franzen, Carl (18 July 2023). \"Cohere is teaming up with McKinsey to bring AI to enterprise clients\". Venture Beat. Retrieved 9 October 2023.^Ordonez, Franco (12 September 2023). \"These tech giants are at the White House today to talk about the risks of AI\". NPR. Retrieved 9 October 2023.^Masse, Bryson (27 September 2023). \"Canada wants to be the first country to implement AI regulations: Minister of Innovation\". Venture Beat. Retrieved 9 October 2023.^ abBort, Julie (13 June 2023). \"Oracle is betting its AI future on a company called Cohere. Here's why this little-known startup is becoming OpenAI's chief rival\". Business Insider. Retrieved 10 October 2023.^Metz, Cade (2 May 2023). \"Generative A.I. Start-Up Cohere Valued at About $2 Billion in Funding Round\". New York Times. Retrieved 10 October 2023.^RBC. \"RBC and Cohere partner to develop the next generation of highly secure generative AI solutions for financial services\". www.newswire.ca. Retrieved 2025-01-09.^Wiggers, Kyle (2025-03-04). \"Cohere claims its new Aya Vision AI model is best-in-class\". TechCrunch. Retrieved 2025-03-20.^Silcoff, Sean (15 February 2022). \"Toronto AI star Cohere raises US$125-million led by Tiger Global\". The Globe and Mail. Retrieved 6 October 2023.^Baker, Liana (30 August 2023). \"OpenAI Rival Cohere Taps JPMorgan, Goldman for Financing\". Bloomberg. Retrieved 6 October 2023.^Wiggers, Kyle (2024-07-22). \"Cohere raises $500M to beat back generative AI rivals\". TechCrunch. Retrieved 2024-08-26.^Hu, Krystal (March 1, 2024). \"\"AI startup Cohere opens New York office in expansion\"\". Reuters.^Canada, Department of Finance (2024-12-06). \"Deputy Prime Minister announces $240 million for Cohere to scale-up AI compute capacity\". www.canada.ca. Retrieved 2025-01-09.^Wiggers, Kyle (2025-02-13). \"Publishers sue AI startup Cohere over alleged copyright infringement\". TechCrunch. Retrieved 2025-02-15.\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Cohere&oldid=1283188676\"", "tags": ["en.wikipedia.org", "wiki", "cohere"]}
{"url": "https://en.wikipedia.org/wiki/Aleph_Alpha", "title": null, "text": "Artificial intelligence company.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}This article is an orphan, as no other articles link to it. Please introduce links to this page from related articles; try the Find link tool for suggestions.  (November 2023).mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme) div:not(.notheme){background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table tr{display:table-row!important}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}.mw-parser-output .ib-company .infobox-label{padding-right:0.5em}.mw-parser-output .ib-company .infobox-data,.mw-parser-output .ib-company .infobox-below{line-height:1.35em}.mw-parser-output .ib-company-logo img{background-color:#f8f9fa}.mw-parser-output .ib-company-locality,.mw-parser-output .ib-company-country{display:inline}Aleph Alpha GmbHCompany typePrivateIndustryArtificial intelligenceFounded2019; 6\u00a0years ago\u00a0(2019)Founders.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Jonas AndrulisSamuel WeinbachHeadquartersHeidelberg, GermanyProductsLuminous LLMNumber of employees51-200[1]\u00a0(2024)Websitealeph-alpha.comAleph Alpha GmbH is a German artificial intelligence (AI) startup company founded by Jonas Andrulis and Samuel Weinbach. Beforehand, both founders had worked at companies like Apple and Deloitte.[2]Based in Heidelberg, the company aims to develop a sovereign technology stack for generative AI that operates independently of U.S. companies and complies with European data protection regulations, including the Artificial Intelligence Act.\nAleph Alpha has established reportedly one of the most powerful AI clusters within its own data center[3] and specializes in developing large language models (LLM). These models are designed to provide transparency regarding the sources used for generating results and are intended for use by enterprises and governmental agencies.[4] The training of these models has been conducted in five European languages.[5]CEO Jonas AndrulisHistory[edit]Aleph Alpha was founded in 2019 by Jonas Andrulis and Samuel Weinbach.\nAndrulis holds a degree in economics engineering from the Karlsruhe Institute of Technology; his thesis focused on artificial intelligence. His professional experience has included consulting at Deloitte and the founding of several AI software companies. Prior to founding Aleph Alpha, he served as an AI R&D engineering manager at Apple's Special Projects Group and worked on classified research with Siri AI R&D.[6]Weinbach, who holds a degree in business administration, worked at Deloitte from 2010; there, he established the Deloitte Analytic Institute, which focused on advancing corporate AI initiatives.[2]Funding[edit]After securing \u20ac5.3 million in seed funding in 2020,[7] Aleph Alpha raised an additional \u20ac23 million in a second round of financing in 2021, backed by several European venture capital firms.[8]In a financing round in November 2023, German companies Schwarz Gruppe and Dieter Schwarz Foundation, with the Innovation Park Artificial Intelligence (IPAI), participated as the co-lead investors along with Bosch,[9]SAP, Hubert Burda Media, Christ&Company Consulting, and Hewlett Packard Enterprise. The round raised a total of $500 million.[10][11]Products[edit]Luminous[edit]Aleph Alpha developed its own AI language model, Luminous, based on its own research and codebase with the architecture of generative pre-trained transformers (GPT) and self-supervised learning. Along with the standard functionality all GPT models share, Aleph Alpha contributed some proprietary innovation:\nIn 2021, they were the first team to offer multimodality,[12] or the ability to prompt their models with any combination of text and images. The innovation behind this capability was published at the leading AI conference EMNLP 2022 and open-sourced under the name MAGMA.[13]In 2022, they were the first team to develop the ability to create images based on multimodal input.[14] This method has been published at NeurIPS 2023 under the name Multifusion.[15]With an innovation called AtMan published at NeurIPS 2023, they developed a method to make the patterns learned by GPT models to create results visible and controllable. This methods addressed the problem that generative AI had been a black box before. It created interest from enterprises and governments to address complex and critical problems where chatbots are sometimes insufficient, making AI generated results more trustworthy.[16][17]As a tool to build and train its foundation models, the HPE Machine Learning Development System is used.[18] Using the GPT-type concept allows for adaptation and fine-tuning of the foundation model to various applications.[19]Luminous is already used for the citizen information system, Lumi, for the city of Heidelberg.[20]Partnerships[edit]For R&D, Aleph Alpha is working with the University of Duisburg-Essen and the Technical University of Darmstadt. It is also participating in open-source organizations such as EleutherAI, a collective of researchers working to increase accessibility to AI research.[5]Both Hewlett Packard Enterprise (HPE) and SAP have entered non-exclusive partnerships with Aleph Alpha. In the case of HPE, it is the first partnership of this kind. HPE will offer Luminous on its Greenlake platform.[21]See also[edit]ChatGPTGeneral Data Protection RegulationAI alignmentReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}\"Aleph Alpha News, Hiring, Layoffs, Competitors, CEO, Fundraising Insights\". RivalSense. Retrieved 28 October 2024.^ abChatbot-Konkurrenz aus Deutschland: Auf Wiedersehen, ChatGPT - und willkommen Aleph Alpha. finanzen.net, 2023-03-15 (in German). Retrieved 2023-11-10.^Schreiner, Maximilian (2022-09-16). \"OpenAI competitor Aleph Alpha launches Europe's fastest commercial AI data center\". THE DECODER. Retrieved 2024-04-14.^Maximilian Schreiner: AI in practice: AI startup Aleph Alpha shows off latest LLMs with a unique feature. The Decoder, 2023-06-05. Retrieved 2023-11-11^ abAccelerating Europe\u2019s multilingual AI revolution.Hewlett Packard Enterprise, 2022. Retrieved 2023-11-11.^Systems, Eulerpool Research. \"L'histoire de r\u00e9ussite de Jonas Andrulis sous les projecteurs\". Eulerpool Research Systems (in French). Retrieved 2024-04-14.^Tucker, Charlotte (2021-01-27). \"Heidelberg-based Aleph Alpha raises \u20ac5.3 million to lead \"Made in Europe\" AI development\". EU-Startups. Retrieved 2024-04-14.^Earlybird leads Aleph Alpha's 23 million EURO Serie A for the largest European AI models. press release, earlybird.com, 2021-07-27. Retrieved 2023-11-11.^Generative AI Investments Aleph Alpha, Anthropic and Cohere. SAP news, 2023-07-18. Retrieved 2023-11-11.^Aleph Alpha raises a total investment of more than half a billion US Dollars from a consortium of industry leaders and new investors. Press Release, aleph-alpha.com, 2023-11-06. Retrieved 2023-11-11.^Aggi Cantrill and Mark Bergen: German Giants Pour Over $500 Million Into AI Startup Aleph Alpha.Bloomberg News, 2023-11-06. Retrieved 2023-11-11.^online, heise (2021-11-18). \"KI-Modell kann Bilder beschreiben: Aleph Alpha ist Vorreiter f\u00fcr multimodale KI\". Developer (in German). Retrieved 2024-04-14.^online, heise (2022-03-16). \"GPT-3 \u00fcberfl\u00fcgeln: Quellcode des KI-Modells MAGMA steht auf GitHub\". Developer (in German). Retrieved 2024-04-14.^online, heise (2022-12-09). \"KI-Bildsynthese: M-VADER erstellt Bilder aus beliebigen Text- und Bildvorgaben\". Developer (in German). Retrieved 2024-04-14.^\"Aleph Alpha Forschungen: NeurIPS Highlights \u2013 ainfach.ai\" (in German). 2023-12-08. Retrieved 2024-04-14.^Schreiner, Maximilian (2023-06-05). \"AI startup Aleph Alpha shows off latest LLMs with a unique feature\". THE DECODER. Retrieved 2024-04-14.^\"Handelsblatt\". www.handelsblatt.com. Retrieved 2024-04-14.^Hewlett Packard Enterprise accelerates AI journey from POC to production with new solution(s) for AI development and training at scale. Press Release, HPE, 2022-04-27. Retrieved 2023-11-11.^Next-level customizability. aleph-alpha.com. Retrieved 2023-11-11.^KI-B\u00fcrgerassistenz Lumi. heidelberg.de, 2023 (in German). Retrieved 2023-11-11.^Matthias Hohensee: Wir verb\u00fcnden uns mit den besten Unternehmen der Welt. In: WirtschaftsWoche, 2023-06-22 (in German). Retrieved 2023-11-11.External links[edit]Official websiteMaximilian Sachse: Ramin Mirza: Aleph Alpha r\u00fcstet im Vertrieb auf. In: Frankfurter Allgemeine Zeitung, 2023-07-05 (in German). Retrieved 2023-11-11Ulrich Hottelet: Interview: Aleph Alpha fordert vertrauensw\u00fcrdige KI mit europ\u00e4ischen Werten. heise online, 2023-06-24 (in German). Retrieved 2023-11-11\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Aleph_Alpha&oldid=1286928263\"", "tags": ["en.wikipedia.org", "wiki", "aleph", "alpha"]}
{"url": "https://en.wikipedia.org/wiki/LightOn", "title": null, "text": "French artificial intelligence company.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme) div:not(.notheme){background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table tr{display:table-row!important}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}.mw-parser-output .ib-company .infobox-label{padding-right:0.5em}.mw-parser-output .ib-company .infobox-data,.mw-parser-output .ib-company .infobox-below{line-height:1.35em}.mw-parser-output .ib-company-logo img{background-color:#f8f9fa}.mw-parser-output .ib-company-locality,.mw-parser-output .ib-company-country{display:inline}LightOnIndustryArtificial intelligenceFounded2016; 9\u00a0years ago\u00a0(2016)Founders.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Igor CarronLaurent DaudetFlorent KrzakalaSylvain GiganHeadquartersParis, FranceKey peopleIgor Carron (CEO)Laurent Daudet (CTO)ProductsOptical Processing Unit (OPU)Large Language ModelNumber of employees41 (2024)[1]Websitelighton.ai.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}Part of a series onArtificial intelligence (AI)Major goalsArtificial general intelligenceIntelligent agentRecursive self-improvementPlanningComputer visionGeneral game playingKnowledge reasoningNatural language processingRoboticsAI safetyApproachesMachine learningSymbolicDeep learningBayesian networksEvolutionary algorithmsHybrid intelligent systemsSystems integrationApplicationsBioinformaticsDeepfakeEarth sciences Finance Generative AIArtAudioMusicGovernmentHealthcareMental healthIndustryTranslation Military PhysicsProjectsPhilosophyArtificial consciousnessChinese roomFriendly AIControl problem/TakeoverEthicsExistential riskTuring testUncanny valleyHistoryTimelineProgressAI winterAI boomGlossaryGlossary.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteLightOn is a French company focused on artificial intelligence (AI), that aims to developp both generative AI[2] and AI hardware solutions.\nIts first product, the Optical Processing Units (OPU), was released in 2018. In 2024, it became Europe's first listed GenAI startup to launch an IPO.\nHistory[edit]LightOn was established in 2016 in Paris by French engineers and entrepreneurs Igor Carron, Laurent Daudet, Florent Krzakala and Sylvain Gigan.[3] The founders, with backgrounds in optics and AI, aimed to develop hardware solutions that could accelerate AI computations using optical processing. The company's first product, the Optical Processing Unit (OPU), was launched in 2018.[4][5] The approach aims to increase the efficiency of massive parallel processing in tasks that involve large-scale data such has Large Language Model.[6]In 2021, LightOn OPU's were integrated in Jean Zay, one of the French National Centre for Scientific Research  supercomputer, making it the first of the TOP500 world's most powerfull computer using such hardware.[7]In 2024, LightOn launched an IPO[8][9] and became Europe's first listed GenAI startup.[10]Between 2020 and 2024, LightOn has designed 12 Large Language Models. Since the end of 2024, LightOn's solutions were implemented by various entities such as Ile-de-France region,  Safran, Groupama, and the French Space Agency (CNES). The company also partnered with Orange Business and Hewlett Packard Enterprise to integrate its AI software with their cloud and hardware offerings.[1]References[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^ ab.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}\"LIGHTON | LIGHTON, a leading European player in generative AI for businesses, announces the approval of its registration document by the AMF as part of its planned IPO on Euronext Growth\u00ae Paris\". 22 October 2024.^\"LightOn to become Europe's first listed GenAI startup with Paris IPO\".^\"LightOn raises $3.3 million for optics-based AI data processing\". 19 December 2018.^\"Startup integrates optical processing into data center for AI operations\". 28 February 2018.^Hesslow, Daniel; Cappelli, Alessandro; Carron, Igor; Daudet, Laurent; Lafargue, Raphael; Muller, Kilian; Ohana, Ruben; Pariente, Gustave; Poli, Iacopo (2021). \"Photonic co-processors in HPC: Using LightOn OPUs for Randomized Numerical Linear Algebra\". 2021 IEEE Hot Chips 33 Symposium (HCS). pp.\u00a01\u20139. arXiv:2104.14429. doi:10.1109/HCS52781.2021.9566948. ISBN\u00a0978-1-6654-1397-8.^\"LightOn Unveils LightOn Appliance, Photonic Co-processor\".^\"This powerful supercomputer can now run on light instead of electric current\". 25 December 2021.^https://www.reuters.com/technology/artificial-intelligence/frances-lighton-says-valued-65-mln-euronext-ipo-2024-11-21/^\"La start-up fran\u00e7aise d'IA LightOn veut s'introduire en bourse\". Le Monde. 8 November 2024.^https://www.reuters.com/markets/europe/lighton-become-europes-first-listed-genai-startup-with-paris-ipo-2024-11-08/External links[edit]https://www.lighton.ai.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}vteGenerative AIchatbotsLarge language modelChatGPTCharacter.aiClaudeDeepSeekERNIEGeminiGrokManusCopilotMinervaMistralPerplexity AIQwenReplikaVelvetYandexGPTYou.comCategoryvteGenerative AIConceptsAutoencoderDeep learningGenerative adversarial networkGenerative pre-trained transformerLarge language modelNeural networkPrompt engineeringRetrieval-augmented generationReinforcement learning from human feedbackSelf-supervised learningTransformerVariational autoencoderVision transformerWord embeddingModelsTextClaudeDBRXDeepSeekERNIEGeminiGPT123JChatGPT44oo1o34.54.1o4GrokGraniteLlamaManusMistral LargePanGu-\u03a3QwenImageAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyStable DiffusionSpeech15.aiWaveNetVideoDream MachineGen-4Hailuo AIKlingSoraVeoVideoPoetMusicEndelUdioSuno AICompanies01.AIAlibabaAnthropicBaichuanBaiduDeepSeekElevenLabsGoogle DeepMindHugging FaceKuaishouMeta AIMiniMaxMistral AIMoonshot AIOpenAIRunwayStability AISynthesiaxAIZhipu AICategoryCommons\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=LightOn&oldid=1281444626\"", "tags": ["en.wikipedia.org", "wiki", "lighton"]}
{"url": "https://en.wikipedia.org/wiki/Runway_(company)", "title": null, "text": "American artificial intelligence company.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme) div:not(.notheme){background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table tr{display:table-row!important}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}.mw-parser-output .ib-company .infobox-label{padding-right:0.5em}.mw-parser-output .ib-company .infobox-data,.mw-parser-output .ib-company .infobox-below{line-height:1.35em}.mw-parser-output .ib-company-logo img{background-color:#f8f9fa}.mw-parser-output .ib-company-locality,.mw-parser-output .ib-company-country{display:inline}Runway AI, Inc.Company typePrivateIndustryArtificial intelligencemachine learningsoftware developmentFounded2018; 7\u00a0years ago\u00a0(2018)HeadquartersManhattan, New York City, U.S.Area servedWorldwideKey people.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}Crist\u00f3bal Valenzuela (CEO)Anastasis Germanidis (CTO)Alejandro Matamala (CDO)ProductsGen-1Gen-2Gen-3 AlphaFramesGen-4Number of employees86Websiterunwayml.comRunway AI, Inc. (also known as Runway and RunwayML) is an American company headquartered in New York City that specializes in generative artificial intelligence research and technologies.[1] The company is primarily focused on creating products and models for generating videos, images, and various multimedia content. It is most notable for developing the commercial text-to-video and video generative AI models Gen-1, Gen-2,[2][3] Gen-3 Alpha[1] and Gen-4.[4]Runway's tools and AI models have been utilized in films such as Everything Everywhere All At Once,[5] in music videos for artists including A$AP Rocky,[6]Kanye West,[7]Brockhampton, and The Dandy Warhols,[8] and in editing television shows like The Late Show[9] and Top Gear.[10]History[edit]The company was founded in 2018 by the Chileans Crist\u00f3bal Valenzuela,[11] Alejandro Matamala and the Greek Anastasis Germanidis after they met at New York University Tisch School of the Arts ITP.[12] The company raised US$2 million in 2018 to build a platform to deploy machine learning models at scale inside multimedia applications.\nIn December 2020, Runway raised US$8.5 million[13] in a Series A funding round.\nIn December 2021, the company raised US$35 million in a Series B funding round.[14]In August 2022, the company co-released an improved version of their Latent Diffusion Model called Stable Diffusion together with the CompVis Group at Ludwig Maximilian University of Munich and a compute donation by Stability AI.[15][16]On December 21, 2022, Runway raised US$50 million[17] in a Series C round. Followed by a $141 million Series C extension round in June 2023 at a $1.5 billion valuation[18][19] from Google, Nvidia, and Salesforce[20] to build foundational multimodal AI models for content generation to be used in films and video production.[21][22]In February 2023 Runway released Gen-1 and Gen-2 the first commercial and publicly available foundational video-to-video and text-to-video generation model[1][2][3] accessible via a simple web interface.\nIn June 2023 Runway was selected as one of the 100 Most Influential Companies in the world by Time magazine.[23]On 3 April 2025, Runway raised $308 million in a funding round led by General Atlantic, valuing it at over $3 billion.[24][25]Services and technologies[edit]Runway is focused on generative AI for video, media, and art. The company focuses on developing proprietary foundational model technology that professionals in filmmaking, post-production, advertising, editing, and visual effects can utilize. Additionally, Runway offers an iOS app aimed at consumers.[26]The Runway product is accessible via a web platform and through an API as a managed service.\nStable Diffusion[edit]Stable Diffusion is an open-sourcedeep learning, text-to-image model released in 2022 based on the original paper High-Resolution Image Synthesis with Latent Diffusion Models published by Runway and the CompVis Group at Ludwig Maximilian University of Munich.[27][28][16] Stable Diffusion is mostly used to create images conditioned on text descriptions.\nGen-1[edit]Gen-1 is a video-to-video generative AI system that synthesize new videos by applying the composition and style of an image or text prompt to the structure of a source video. The model was released in February 2023. The Gen-1 model was trained and developed by Runway based on the original paper Structure and Content-Guided Video Synthesis with Diffusion Models from Runway Research.[29] Gen-1 is an example of generative artificial intelligence for video creation.\nGen-2[edit]Gen-2 is a multimodal AI system that can generate novel videos with text, images or video clips. The model is a continuation of Gen-1 and includes a modality to generate video conditioned to text. Gen-2 is one of the first commercially available text-to-video models.[30][31][32][33]Gen-3 Alpha[edit]Gen-3 Alpha is the first of an upcoming series of models trained by Runway on a new infrastructure built for large-scale multimodal training. It is a major improvement in fidelity, consistency, and motion over Gen-2, and a step towards building General World Model\u0441\u0441\u0432s.[2]Training data for Gen-3 has been sourced from thousands of YouTube videos and potentially pirated films. A former Runway employee alleged to 404 Media that a company-wide effort was to compile videos into spreadsheets, which was then downloaded using youtube-dl through proxy servers to avoid being blocked by YouTube. In tests, 404 Media discovered that names of YouTubers would generate videos in their respective styles.[34]Gen-4[edit]On March 31, 2025, Runway released its latest flagship model, Gen-4.\nGen-4 able to precisely generate consistent characters, locations and objects across scenes. Simply need set look and feel and the model will maintain coherent world environments while preserving the distinctive style, mood and cinematographic elements of each frame. Then can regenerate those elements from multiple perspectives and positions within scenes.[4]Gen-4 can utilize visual references, combined with instructions, to create new images and videos utilizing consistent styles, subjects, locations and more. Giving unprecedented creative freedom to tell story.[4]Runway Gen-4 allows to generate consistent characters across endless lighting conditions, locations and treatments. All with just a single reference image of characters.[4]Gen-4 excels in its ability to generate highly dynamic videos with realistic motion as well as subject, object and style consistency with superior prompt adherence and best in class world understanding.[4]AI Film Festival[edit]Runway hosts an annual AI Film Festival[35] in Los Angeles and New York City.[36][37]References[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^ abc.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Metz, Cade (2023-04-04). \"Instant Videos Could Represent the Next Leap in A.I. Technology\". The New York Times. ISSN\u00a00362-4331. Retrieved 2023-09-15.^ abc\"Generative AI's Next Frontier Is Video\". Bloomberg.com. 2023-03-20. Retrieved 2023-09-15.^ abVincent, James (2023-03-20). \"Text-to-video AI inches closer as startup Runway announces new model\". The Verge. Retrieved 2023-09-15.^ abcde\"Introducing Runway Gen-4\". runwayml.com. 2025-03-31. Retrieved 2025-03-31.^\"How director and editor Evan Halleck uses Runway for films, music videos, and commercials\". Runway. Retrieved 2024-03-01.^\"Distorting Reality with Dan Streit\". Runway. Retrieved 2024-03-01.^Cowen, Trace William. \"Kanye West Shares Unsettling Video for \"Vultures (Havoc Version)\" Ahead of Ty Dolla Sign Collab Album Release\". Complex. Retrieved 2024-03-01.^The Dandy Warhols - \"I'd Like To Help You With Your Problem (feat. Slash)\" - Official Music Video, 14 February 2024, retrieved 2024-03-01^\"How Runway took The Late Show edits from five hours to five minutes\". Runway. Retrieved 2024-03-01.^\"How Drew Emery uses Runway to edit content for Top Gear America & Cooper's Bar\". Runway. Retrieved 2024-03-01.^\"TIME100 AI 2023: Crist\u00f3bal Valenzuela\". Time. 2023-09-07. Retrieved 2023-09-15.^Black, Julia. \"'Not Everyone Is Trying to Build God': Runway CEO Crist\u00f3bal Valenzuela Tries to Dampen the Doomerism\". The Information. Retrieved 2023-09-18.^\"RunwayML raises $8.5 million for its AI-powered media creation tools\". VentureBeat. 2020-12-16. Retrieved 2023-09-15.^\"Runway raises $35M Series B | Runway Blog\". Runway. Retrieved 2023-11-07.^Cai, Kenrick. \"The AI Founder Taking Credit For Stable Diffusion's Success Has A History Of Exaggeration\". Forbes. Retrieved 2023-09-15.^ ab\"The original startup behind Stable Diffusion has launched a generative AI for video\". MIT Technology Review. Retrieved 2023-09-18.^Cai, Kenrick. \"Runway Raises $50 Million At $500 Million Valuation As Generative AI Craze Continues\". Forbes. Retrieved 2023-09-15.^\"AI Video Startup Runway Raises $141 Million From Google, Nvidia\". Bloomberg.com. 2023-06-29. Retrieved 2023-09-15.^Wiggers, Kyle (2023-06-29). \"Runway, a startup building generative AI for content creators, raises $141M\". TechCrunch. Retrieved 2023-09-15.^\"Google Invests in AI Startup Runway to Wrest Cloud Business From AWS\". The Information. Retrieved 2023-09-15.^Black, Julia. \"'Not Everyone Is Trying to Build God': Runway CEO Crist\u00f3bal Valenzuela Tries to Dampen the Doomerism\". The Information. Retrieved 2023-09-15.^\"Featured interview: Runway AI CEO Chris Valenzuela - First Move with Julia Chatterley - Podcast on CNN Audio\". CNN. Retrieved 2023-09-18.^\"TIME100 Most Influential Companies 2023: Runway\". Time. 2023-06-21. Retrieved 2023-09-20.^Vasani, Sheena (2025-04-01). \"Runway says its latest AI video model can actually generate consistent scenes and people\". The Verge. Retrieved 2025-04-04.^Wiggers, Kyle (2025-04-03). \"Runway, best known for its video-generating AI models, raises $308M\". TechCrunch. Retrieved 2025-04-04.^Vincent, James (2023-04-24). \"Create generative AI video-to-video right from your phone with Runway's iOS app\". The Verge. Retrieved 2024-03-01.^\"Stable Diffusion developer Runway raises $50M to create AI multimedia tools\". SiliconANGLE. 2022-12-06. Retrieved 2023-09-18.^\"Stability AI Is Losing Executives, Engineers and Its Edge\". Bloomberg.com. 2023-08-08. Retrieved 2023-09-18.^\"Gen-1 by Runway\". Runway. Retrieved 2023-09-18.^\"Text to Video Generative AI Is Finally Here and It's Weird as Hell\". Gizmodo. 2023-03-22. Retrieved 2023-09-18.^Wiggers, Kyle (2023-06-09). \"Runway's Gen-2 shows the limitations of today's text-to-video tech\". TechCrunch. Retrieved 2023-09-18.^Avram Piltch (2023-06-08). \"Runway's Powerful Gen-2 Text-to-Video Tool Now Available to Everyone for Free\". Tom's Hardware. Retrieved 2023-09-18.^Vincent, James (2023-03-20). \"Text-to-video AI inches closer as startup Runway announces new model\". The Verge. Retrieved 2023-09-18.^Cole, Samantha (July 25, 2024). \"AI Video Generator Runway Trained on Thousands of YouTube Videos Without Permission\". 404 Media. Retrieved July 25, 2024.^\"Runway AI Film Festival\". Runway. Retrieved 2023-11-18.^Melendez, Steven. \"A new film festival will only show movies made using AI\".^Kokalitcheva, Kia (26 March 2023). \"1 big movie thing: an AI-generated film festival\".External links[edit]Official website.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteGenerative AIConceptsAutoencoderDeep learningGenerative adversarial networkGenerative pre-trained transformerLarge language modelNeural networkPrompt engineeringRetrieval-augmented generationReinforcement learning from human feedbackSelf-supervised learningTransformerVariational autoencoderVision transformerWord embeddingModelsTextClaudeDBRXDeepSeekERNIEGeminiGPT123JChatGPT44oo1o34.54.1o4GrokGraniteLlamaManusMistral LargePanGu-\u03a3QwenImageAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyStable DiffusionSpeech15.aiWaveNetVideoDream MachineGen-4Hailuo AIKlingSoraVeoVideoPoetMusicEndelUdioSuno AICompanies01.AIAlibabaAnthropicBaichuanBaiduDeepSeekElevenLabsGoogle DeepMindHugging FaceKuaishouMeta AIMiniMaxMistral AIMoonshot AIOpenAIRunwayStability AISynthesiaxAIZhipu AICategoryCommonsvteArtificial intelligence (AI)History (timeline)ConceptsParameterHyperparameterLoss functionsRegressionBias\u2013variance tradeoffDouble descentOverfittingClusteringGradient descentSGDQuasi-Newton methodConjugate gradient methodBackpropagationAttentionConvolutionNormalizationBatchnormActivationSoftmaxSigmoidRectifierGatingWeight initializationRegularizationDatasetsAugmentationPrompt engineeringReinforcement learningQ-learningSARSAImitationPolicy gradientDiffusionLatent diffusion modelAutoregressionAdversaryRAGUncanny valleyRLHFSelf-supervised learningRecursive self-improvementWord embeddingHallucinationApplicationsMachine learningIn-context learningArtificial neural networkDeep learningLanguage modelLarge language modelNMTArtificial general intelligence (AGI)ImplementationsAudio\u2013visualAlexNetWaveNetHuman image synthesisHWROCRSpeech synthesis15.aiElevenLabsSpeech recognitionWhisperFacial recognitionAlphaFoldText-to-image modelsAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyStable DiffusionText-to-video modelsDream MachineRunway GenHailuo AIKlingSoraVeoMusic generationSuno AIUdioTextWord2vecSeq2seqGloVeBERTT5LlamaChinchilla AIPaLMGPT123JChatGPT44oo1o34.54.1ClaudeGeminichatbotGrokLaMDABLOOMProject DebaterIBM WatsonIBM WatsonxGranitePanGu-\u03a3DeepSeekQwenDecisionalAlphaGoAlphaZeroOpenAI FiveSelf-driving carMuZeroAction selectionAutoGPTRobot controlPeopleAlan TuringWarren Sturgis McCullochWalter PittsJohn von NeumannClaude ShannonMarvin MinskyJohn McCarthyNathaniel RochesterAllen NewellCliff ShawHerbert A. SimonOliver SelfridgeFrank RosenblattBernard WidrowJoseph WeizenbaumSeymour PapertSeppo LinnainmaaPaul WerbosJ\u00fcrgen SchmidhuberYann LeCunGeoffrey HintonJohn HopfieldYoshua BengioLotfi A. ZadehStephen GrossbergAlex GravesAndrew NgFei-Fei LiAlex KrizhevskyIlya SutskeverDemis HassabisDavid SilverIan GoodfellowAndrej KarpathyJames GoodnightArchitecturesNeural Turing machineDifferentiable neural computerTransformerVision transformer (ViT)Recurrent neural network (RNN)Long short-term memory (LSTM)Gated recurrent unit (GRU)Echo state networkMultilayer perceptron (MLP)Convolutional neural network (CNN)Residual neural network (RNN)Highway networkMambaAutoencoderVariational autoencoder (VAE)Generative adversarial network (GAN)Graph neural network (GNN) Portals\nTechnologyCategoryArtificial neural networksMachine learning List\nCompaniesProjects\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Runway_(company)&oldid=1286420742\"", "tags": ["en.wikipedia.org", "wiki", "runway", "company"]}
{"url": "https://en.wikipedia.org/wiki/Synthesia_(company)", "title": null, "text": "English artificial intelligence company (2017-)\n\n.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme) div:not(.notheme){background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table tr{display:table-row!important}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}.mw-parser-output .ib-company .infobox-label{padding-right:0.5em}.mw-parser-output .ib-company .infobox-data,.mw-parser-output .ib-company .infobox-below{line-height:1.35em}.mw-parser-output .ib-company-logo img{background-color:#f8f9fa}.mw-parser-output .ib-company-locality,.mw-parser-output .ib-company-country{display:inline}SynthesiaLogo of companyCompany typePrivateIndustryArtificial intelligenceFounded2017; 8\u00a0years ago\u00a0(2017)FounderLourdes AgapitoMatthias NiessnerVictor RiparbelliSteffen TjerrildHeadquartersLondon, EnglandArea servedWorldwideProductsSynthetic mediaArtificial IntelligenceVideo editing softwareNumber of employees400[1]\u00a0(2025)Websitesynthesia.ioSynthesia is a synthetic media generation company that develops software used to create AI generated video content. Its customer base, as of January 2025, includes over sixty percent of Fortune 100 companies. It is based in London, England.\nOverview[edit]Synthesia is most often used by corporations for communication, orientation, and training videos.[2] It has been used in advertising campaigns, reporting, product demonstrations, and to create chatbots.[3][4]Synthesia's software algorithm mimics speech and facial movements based on video recordings of an individual's speech and phoneme pronunciation. From this a text-to-speech video is created to look and sound like the individual.[5][6]Users create content via the platform's pre-generated AI presenters[3] or by creating digital representations of themselves, or personal avatars, using the platform's AI video editing tool.[7] These avatars can be used to narrate videos generated from text. As of August 2021, Synthesia's voice database included multiple gender options in over sixty languages.[7][8]The platform prohibits use of its software to create non-consensual clones, including of celebrities or political figures for satirical purposes.[9] Explicit consent must be provided in addition to a strict pre-screening regimen for use of an individual's likeness to avoid \u201cdeepfaking\u201d.[10]History[edit]2017\u20132018: Founding and early history[edit]Synthesia's software utilizes deep learning architecture developed by Lourdes Agapito and Matthias Niessner. The company was co-founded in 2017 by Agapito, Niessner, Victor Riparbelli, and Steffen Tjerrild.[11] In 2018, the company first demonstrated the software's capabilities on the BBC programme Click when it presented a digitization of Matthew Amroliwala speaking Spanish, Mandarin, and Hindi.[12]2019\u20132020: Initial funding[edit]Synthesia raised $3.1 million in seed funding in 2019.[4] In 2020, Synthesia users were reported to include Amazon, Tiffany & Co. and IHG Hotels & Resorts.[13][14]2021\u20132022: Series A, B, and partnerships[edit]In April 2021, the company raised $12.5 million in Series A funding.[7] In December 2021, it raised $50 million in a Series B funding round led by Kleiner Perkins and GV.[15]In 2021, Synthesia partnered with Lay's to create the Messi Messages campaign featuring Argentine footballer Lionel Messi. Users created personalized messages with Synthesia's software and sent custom artificial reality video messages from Messi based on their text input.[16] The campaign received a Cannes Lion Award.[17]2023\u20132024: Misuse controls[edit]Synthesia gained a total valuation of $1 billion, and achieved unicorn status, when it raised $90 million from Accel and Nvidia partnership NVentures, in June 2023, during its Series C funding round.[18][19][13]While the company prohibits use of its technology for misinformation or \"news-like content\",[20] an October 2023 Freedom House report stated that Synthesia tools had been used by governments in Venezuela and China to create videos of fake TV news outlets with AI-generated avatars in order to spread propaganda.[21] The company stated, in February 2024, that it had improved its misuse detection systems,[20] and, in April 2024, that new users of its technology are screened by the company, and content employing it is further vetted by Synthesia moderators.[22]In January 2024, the company introduced its AI video assistant, which turns text-to-video.[23] That April, with a reported 55,000 customers, including half of the Fortune 100, Synthesia launched \"expressive avatars\".[22]2025\u2013Present: Expansion and leadership changes[edit]Counting 60,000 customers the following January, including over 60% of Fortune 100 companies; the company raised $180 million in a Series D round led by NEA,[1] with new investors World Innovation Lab (WiL), Atlassian Ventures and PSP Growth, as well as existing investors GV, MMC Ventures and FirstMark, doubling Synthesia's valuation to $2.1 billion.[24][25] Capital raised to date reached $330 million in 2025,[25] with 2025 investments slated to further product innovation, talent growth, and company expansion in North America, Europe, Japan and Australia.[1]Peter Hill joined Synthesia as CTO in January 2025, following 25 years at Amazon, and two years as CEO and CPO of Wildfire Studios.[26]In February 2025, UK Science and Technology MinisterPeter Kyle commended Synthesia's \"pioneering generative AI innovations.\"[26][25][27] In april, Adobe invested \"an undisclosed amount of funds\" in Synthesia for a \u201cstrategic\u201d partnership.[28]References[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^ abcSynthesia hits $2.1 bln in valuation after latest fundraiseReuters. January 14, 2025^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}Crook, Jordan (8 December 2021). \"Synthesia raises $50M to leverage synthetic avatars for corporate training and more\". TechCrunch. Retrieved 6 March 2023.^ abKhalid, Amrita. \"The Next Great Tool for Winning Customers and Training Employees: Deepfakes\". Inc.^ abRoettgers, Janko (22 August 2019). \"How AI Tech Is Changing Dubbing, Making Stars Like David Beckham Multilingual\". Variety. Retrieved 6 March 2023.^Simonite, Tom. \"Deepfakes Are Now Making Business Pitches\". Wired. ISSN\u00a01059-1028. Retrieved 6 March 2023.^\"Dubbing is coming to a small screen near you\". The Economist. 21 December 2019.^ abcCrook, Jordan (20 April 2021). \"Synthesia's AI video generation platform hooks $12.5 million Series A led by FirstMark\". TechCrunch. Retrieved 6 March 2023.^Dale, Robert (8 April 2022). \"The voice synthesis business: 2022 update\". Natural Language Engineering. 28 (3): 401\u2013408. doi:10.1017/S1351324922000146. ISSN\u00a01351-3249.^Heilweil, Rebecca (29 June 2020). \"How deepfakes could actually do some good\". Vox. Retrieved 6 March 2023.^\"Synthesia, which is developing AI to generate synthetic videos, secures $50M\". VentureBeat. 8 December 2021. Retrieved 6 March 2023.^Butcher, Mike (25 April 2019). \"The startup behind that deep-fake David Beckham video just raised $3M\". TechCrunch. Retrieved 6 March 2023.^\"BBC World News - Click, Top Quality Fake News, BBC newsreader 'speaks' languages he can't\". BBC. 9 November 2018. Retrieved 6 March 2023.^ abSingh, Jaspreet. \"AI startup Synthesia gains unicorn status after Nvidia-backed fundraise\". Yahoo Finance. Retrieved 16 June 2023.^\"AI Video Creation Pioneer Synthesia Raises $90 Million Series C Led by Accel\". Business Wire. Retrieved 16 June 2023.^Lee, Jane Lanhee (8 December 2021). \"AI video avatar platform Synthesia raises $50 mln in venture capital\". Reuters. Retrieved 6 March 2023.^\"You can now send personalised videos from an AI version of Messi. It's weird\". ESPN.com. 16 March 2021. Retrieved 6 March 2023.^\"The Work | Lions Entry | Messi Messages\". The Work. Retrieved 6 March 2023.^Burroughs, Callum (13 June 2023). \"Generative AI startup Synthesia just raised $90 million in fresh funds from US fund Accel and Nvidia at a $1 billion valuation\". Business Insider. Retrieved 14 June 2023.^Wiggers, Kyle. \"Synthesia secures $90M for AI that generates custom avatars\". TechCrunch. Retrieved 6 March 2023.^ abIn Big Election Year, A.I.\u2019s Architects Move Against Its Misuse The New York Times accessed 19 August 2024.^\"Generative AI Is the Newest Tool in the Dictator's Handbook\". Gizmodo. 4 October 2023. Retrieved 7 October 2023.^ abNvidia-backed startup Synthesia unveils AI avatars that can convey human emotions CNBC accessed 19 August 2024.^Synthesia launches LLM-powered assistant to turn any text file or link into AI video Venture Beat accessed 19 August 2024.^AI video platform Synthesia raises $180M, doubling valuation to $2.1B Silicon Angle. January 15, 2025^ abcSaunders, Tom (15 January 2025). \"British start-up Synthesia hits $2.1bn valuation on AI video boom\". www.thetimes.com. Retrieved 11 February 2025.^ abNvidia-backed AI video platform Synthesia doubles valuation to $2.1 billionCNBC. January 15, 2025^\"Department for Science, Innovation and Technology on LinkedIn: #aiactionsummit | 13 comments\". www.linkedin.com. Retrieved 11 February 2025.^Browne, Ryan (15 April 2025). \"Adobe takes stake in Synthesia, startup behind AI clones for corporate videos\". CNBC. Retrieved 15 April 2025.External links[edit]Official website.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteGenerative AIConceptsAutoencoderDeep learningGenerative adversarial networkGenerative pre-trained transformerLarge language modelNeural networkPrompt engineeringRetrieval-augmented generationReinforcement learning from human feedbackSelf-supervised learningTransformerVariational autoencoderVision transformerWord embeddingModelsTextClaudeDBRXDeepSeekERNIEGeminiGPT123JChatGPT44oo1o34.54.1o4GrokGraniteLlamaManusMistral LargePanGu-\u03a3QwenImageAuroraDALL-EFireflyFluxIdeogramImagenMidjourneyStable DiffusionSpeech15.aiWaveNetVideoDream MachineGen-4Hailuo AIKlingSoraVeoVideoPoetMusicEndelUdioSuno AICompanies01.AIAlibabaAnthropicBaichuanBaiduDeepSeekElevenLabsGoogle DeepMindHugging FaceKuaishouMeta AIMiniMaxMistral AIMoonshot AIOpenAIRunwayStability AISynthesiaxAIZhipu AICategoryCommons\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Synthesia_(company)&oldid=1286825143\"", "tags": ["en.wikipedia.org", "wiki", "synthesia", "company"]}
{"url": "https://en.wikipedia.org/wiki/LangChain", "title": null, "text": "Language model application development framework.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}@media screen{html.skin-theme-clientpref-night .mw-parser-output .infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .infobox-full-data:not(.notheme) div:not(.notheme){background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive .mw-parser-output .infobox-table{display:table!important}body.skin--responsive .mw-parser-output .infobox-table>caption{display:table-caption!important}body.skin--responsive .mw-parser-output .infobox-table>tbody{display:table-row-group}body.skin--responsive .mw-parser-output .infobox-table tr{display:table-row!important}body.skin--responsive .mw-parser-output .infobox-table th,body.skin--responsive .mw-parser-output .infobox-table td{padding-left:inherit;padding-right:inherit}}LangChainDeveloper(s)Harrison ChaseInitial releaseOctober 2022Stable release0.1.16[1]\n   / 11 April 2024; 12 months ago\u00a0(11 April 2024)Repositorygithub.com/langchain-ai/langchainWritten inPython and JavaScriptTypeSoftware framework for large language model application developmentLicenseMIT LicenseWebsiteLangChain.com.mw-parser-output .portalbox{padding:0;margin:0.5em 0;display:table;box-sizing:border-box;max-width:175px;list-style:none}.mw-parser-output .portalborder{border:1px solid var(--border-color-base,#a2a9b1);padding:0.1em;background:var(--background-color-neutral-subtle,#f8f9fa)}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;height:1.9em;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}Free and open-source software portalLangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]History[edit]LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. The project quickly garnered popularity,[3] with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project's Discord server, many YouTube tutorials, and meetups in San Francisco and London. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[4][5]In the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.[6][7]In October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.[8]Capabilities[edit]LangChain's developers highlight the framework's applicability to use-cases including chatbots,[9]retrieval-augmented generation,[10]  document summarization,[11] and synthetic data generation.[12]As of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage;[13] API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search;[14] OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[15] to store and retrieve vector embeddings; Weaviate vector database[16] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[17] As of April 2023, it can read from more than 50 document types and data sources.[18]LangChain tools[edit]Tool name\nAccount required?\nAPI key required?\nLicencing\nFeatures\nDocumentation URL\nAlpha  Vantage\nNo\nYes\nProprietary\nFinancial data, analytics\nhttps://python.langchain.com/docs/integrations/tools/alpha_vantage\nApify\nNo\nYes\nCommercial\nWeb scraping, automation\nhttps://python.langchain.com/docs/integrations/providers/apify/\nArXiv\nNo\nNo\nOpen  Source\nScientific  papers, research\nhttps://python.langchain.com/docs/integrations/tools/arxiv\nAWS  Lambda\nYes\nYes\nProprietary\nServerless  computing\nhttps://python.langchain.com/docs/integrations/tools/awslambda\nBash\nNo\nNo\nOpen  source\nShell environment access\nhttps://python.langchain.com/docs/integrations/tools/bash\nBearly Code Interpreter\nNo\nYes\nCommercial\nRemote Python code execution\nhttps://python.langchain.com/docs/integrations/tools/bearly\nBing Search\nNo\nYes\nProprietary\nSearch engine\nhttps://python.langchain.com/docs/integrations/tools/bing_search\nBrave Search\nNo\nNo\nOpen  source\nPrivacy-focused  search\nhttps://python.langchain.com/docs/integrations/tools/brave_search\nChatGPT Plugins\nNo\nYes\nProprietary\nChatGPT\nhttps://python.langchain.com/docs/integrations/tools/chatgpt_plugins\nConnery\nNo\nYes\nCommercial\nAPI actions\nhttps://python.langchain.com/docs/integrations/tools/connery\nDall-E Image Generator\nNo\nYes\nProprietary\nText-to-image  generation\nhttps://python.langchain.com/docs/integrations/tools/dalle_image_generator\nDataForSEO\nNo\nYes\nCommercial\nSEO data, analytics\nhttps://python.langchain.com/docs/integrations/tools/dataforseo\nDuckDuckGo  Search\nNo\nNo\nOpen  source\nPrivacy-focused search\nhttps://python.langchain.com/docs/integrations/tools/ddg\nE2B Data Analysis\nNo\nNo\nOpen  source\nData analysis\nhttps://python.langchain.com/docs/integrations/tools/e2b_data_analysis\nEden AI\nNo\nYes\nCommercial\nAI tools, APIs\nhttps://python.langchain.com/docs/integrations/tools/edenai_tools\nEleven Labs Text2Speech\nNo\nYes\nCommercial\nText-to-speech\nhttps://python.langchain.com/docs/integrations/tools/eleven_labs_tts\nExa Search\nNo\nYes\nCommercial\nWeb search\nhttps://python.langchain.com/docs/integrations/tools/exa_search\nFile System\nNo\nNo\nOpen  source\nFile system interaction\nhttps://python.langchain.com/docs/integrations/tools/filesystem\nGolden Query\nNo\nYes\nCommercial\nNatural  language queries\nhttps://python.langchain.com/docs/integrations/tools/golden_query\nGoogle Cloud Text-to-Speech\nYes\nYes\nProprietary\nText-to-speech\nhttps://python.langchain.com/docs/integrations/tools/google_cloud_texttospeech\nGoogle Drive\nYes\nYes\nProprietary\nGoogle Drive access\nhttps://python.langchain.com/docs/integrations/tools/google_drive\nGoogle Finance\nYes\nYes\nProprietary\nFinancial data\nhttps://python.langchain.com/docs/integrations/tools/google_finance\nGoogle Jobs\nYes\nYes\nProprietary\nJob search\nhttps://python.langchain.com/docs/integrations/tools/google_jobs\nGoogle Lens\nYes\nYes\nProprietary\nVisual  search, recognition\nhttps://python.langchain.com/docs/integrations/tools/google_lens\nGoogle Places\nYes\nYes\nProprietary\nLocation-based  services\nhttps://python.langchain.com/docs/integrations/tools/google_places\nGoogle Scholar\nYes\nYes\nProprietary\nScholarly  article search\nhttps://python.langchain.com/docs/integrations/tools/google_scholar\nGoogle Search\nYes\nYes\nProprietary\nSearch engine\nhttps://python.langchain.com/docs/integrations/tools/google_search\nGoogle Serper\nNo\nYes\nCommercial\nSERP scraping\nhttps://python.langchain.com/docs/integrations/tools/google_serper\nGoogle Trends\nYes\nYes\nProprietary\nTrend data\nhttps://python.langchain.com/docs/integrations/tools/google_trends\nGradio\nNo\nNo\nOpen  source\nMachine learning UIs\nhttps://python.langchain.com/docs/integrations/tools/gradio_tools\nGraphQL\nNo\nNo\nOpen  source\nAPI queries\nhttps://python.langchain.com/docs/integrations/tools/graphql\nHuggingFace  Hub\nNo\nNo\nOpen  source\nHugging Face models, datasets\nhttps://python.langchain.com/docs/integrations/tools/huggingface_tools\nHuman as a tool\nNo\nNo\nN/A\nHuman input\nhttps://python.langchain.com/docs/integrations/tools/human_tools\nIFTTT WebHooks\nNo\nYes\nCommercial\nWeb service automation\nhttps://python.langchain.com/docs/integrations/tools/ifttt\nIonic Shopping\nNo\nYes\nCommercial\nShopping\nhttps://python.langchain.com/docs/integrations/tools/ionic_shopping\nLemon Agent\nNo\nYes\nCommercial\nLemon AI interaction\nhttps://python.langchain.com/docs/integrations/tools/lemonai\nMemorize\nNo\nNo\nOpen  source\nFine-tune LLM to memorize information using unsupervised learning\nhttps://python.langchain.com/docs/integrations/tools/memorize\nNuclia\nNo\nYes\nCommercial\nIndexing of unstructured data\nhttps://python.langchain.com/docs/integrations/tools/nuclia\nOpenWeatherMap\nNo\nYes\nCommercial\nWeather data\nhttps://python.langchain.com/docs/integrations/tools/openweathermap\nPolygon Stock Market API\nNo\nYes\nCommercial\nStock market data\nhttps://python.langchain.com/docs/integrations/tools/polygon\nPubMed\nNo\nNo\nOpen  source\nBiomedical  literature\nhttps://python.langchain.com/docs/integrations/tools/pubmed\nPython REPL\nNo\nNo\nOpen  source\nPython shell\nhttps://python.langchain.com/docs/integrations/tools/python\nReddit Search\nNo\nNo\nOpen  source\nReddit search\nhttps://python.langchain.com/docs/integrations/tools/reddit_search\nRequests\nNo\nNo\nOpen  source\nHTTP requests\nhttps://python.langchain.com/docs/integrations/tools/requests\nSceneXplain\nNo\nNo\nOpen  source\nModel explanations\nhttps://python.langchain.com/docs/integrations/tools/sceneXplain\nSearch\nNo\nNo\nOpen  source\nQuery various search services\nhttps://python.langchain.com/docs/integrations/tools/search_tools\nSearchApi\nNo\nYes\nCommercial\nQuery various search services\nhttps://python.langchain.com/docs/integrations/tools/searchapi\nSearxNG\nNo\nNo\nOpen  source\nPrivacy-focused  search\nhttps://python.langchain.com/docs/integrations/tools/searx_search\nSemantic Scholar API\nNo\nNo\nOpen  source\nAcademic  paper search\nhttps://python.langchain.com/docs/integrations/tools/semanticscholar\nSerpAPI\nNo\nYes\nCommercial\nSearch engine results page scraping\nhttps://python.langchain.com/docs/integrations/tools/serpapi\nStackExchange\nNo\nNo\nOpen  source\nStack  Exchange access\nhttps://python.langchain.com/docs/integrations/tools/stackexchange\nTavily Search\nNo\nYes\nCommercial\nQuestion  answering\nhttps://python.langchain.com/docs/integrations/tools/tavily_search\nTwilio\nNo\nYes\nCommercial\nCommunication  APIs\nhttps://python.langchain.com/docs/integrations/tools/twilio\nWikidata\nNo\nNo\nOpen  source\nStructured  data access\nhttps://python.langchain.com/docs/integrations/tools/wikidata\nWikipedia\nNo\nNo\nOpen  source\nWikipedia  access\nhttps://python.langchain.com/docs/integrations/tools/wikipedia\nWolfram Alpha\nNo\nYes\nProprietary\nComputational  knowledge\nhttps://python.langchain.com/docs/integrations/tools/wolfram_alpha\nYahoo Finance News\nNo\nYes\nCommercial\nFinancial news\nhttps://python.langchain.com/docs/integrations/tools/yahoo_finance_news\nYoutube\nNo\nYes\nCommercial\nYouTube  access\nhttps://python.langchain.com/docs/integrations/tools/youtube\nZapier Natural Language Actions\nNo\nYes\nCommercial\nWorkflow  automation\nhttps://python.langchain.com/docs/integrations/tools/zapier\nReferences[edit].mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}^.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}\"Release 0.1.16\". 11 April 2024. Retrieved 23 April 2024.^Buniatyan, Davit (2023). \"Code Understanding Using LangChain\". Activeloop.^Auffarth, Ben (2023). Generative AI with LangChain. Birmingham: Packt Publishing. p.\u00a083. ISBN\u00a09781835083468.^Palazzolo, Stephanie (2023-04-13). \"AI startup LangChain taps Sequoia to lead funding round at a valuation of at least $200 million\". Business Insider. Archived from the original on 2023-04-18. Retrieved 2023-04-18.^Griffith, Erin; Metz, Cade (2023-03-14). \"'Let 1,000 Flowers Bloom': A.I. Funding Frenzy Escalates\". The New York Times. ISSN\u00a00362-4331. Archived from the original on 2023-04-18. Retrieved 2023-04-18.^Mansurova, Mariya (2023-10-30). \"Topic Modelling in production: Leveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular service\". towardsdatascience.com. Retrieved 2024-07-08.^\"LangChain Expression Language\". langchain.dev. 2023-08-01. Retrieved 2024-07-08.^\"Introducing LangServe, the best way to deploy your LangChains\". LangChain Blog. 2023-10-12. Retrieved 2023-10-17.^\"Chatbots | \ud83e\udd9c\ufe0f\ud83d\udd17 Langchain\". python.langchain.com. Retrieved 2023-11-26.^\"Retrieval-augmented generation (RAG) | \ud83e\udd9c\ufe0f\ud83d\udd17 Langchain\". python.langchain.com. Retrieved 2023-11-26.^\"Summarization | \ud83e\udd9c\ufe0f\ud83d\udd17 Langchain\". python.langchain.com. Retrieved 2023-11-26.^\"Synthetic data generation | \ud83e\udd9c\ufe0f\ud83d\udd17 Langchain\". python.langchain.com. Retrieved 2023-11-26.^\"Azure Cognitive Search and LangChain: A Seamless Integration for Enhanced Vector Search Capabilities\". TECHCOMMUNITY.MICROSOFT.COM. Retrieved 2024-08-31.^\"Best Alternative AI Content Strategies and LLM Frameworks\". Medium. 2024-08-31. Retrieved 2024-08-31.^\"Milvus \u2014 LangChain\". python.langchain.com. Retrieved 2023-10-29.^\"Weaviate\". python.langchain.com. Retrieved 2024-01-17.^Hug, Daniel Patrick (2023-03-08). \"Hierarchical topic tree of LangChain's integrations\"(PDF). GitHub. Archived from the original on 2023-04-29. Retrieved 2023-04-18.^\"Document Loaders \u2014 LangChain 0.0.142\". python.langchain.com. Archived from the original on 2023-04-18. Retrieved 2023-04-18.External links[edit].mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:var(--background-color-interactive-subtle,#f8f9fa);display:flow-root}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1;min-width:0}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}.mw-parser-output .sister-box .side-box-abovebelow{padding:0.75em 0;text-align:center}.mw-parser-output .sister-box .side-box-abovebelow>b{display:block}.mw-parser-output .sister-box .side-box-text>ul{border-top:1px solid #aaa;padding:0.75em 0;width:217px;margin:0 auto}.mw-parser-output .sister-box .side-box-text>ul>li{min-height:31px}.mw-parser-output .sister-logo{display:inline-block;width:31px;line-height:31px;vertical-align:middle;text-align:center}.mw-parser-output .sister-link{display:inline-block;margin-left:4px;width:182px;vertical-align:middle}@media print{body.ns-0 .mw-parser-output .sistersitebox{display:none!important}}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sistersitebox img[src*=\"Wiktionary-logo-v2.svg\"]{background-color:white}}.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}LangChain  at Wikipedia's sister projectsMedia from CommonsData from WikidataOfficial websiteDiscord server support hubLangchain-ai on GitHub.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" \u00b7 \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}vteOpenAIProductsChatbotsChatGPTin educationGPT StoreDALL-EChatGPT SearchSoraWhisperGitHub CopilotFoundationmodelsOpenAI CodexGenerative pre-trained transformerGPT-1GPT-2GPT-3GPT-4GPT-4oo1o3o4GPT-4.5GPT-4.1IntelligentagentsChatGPT Deep ResearchOperatorPeopleSeniormanagementCurrentSam AltmanremovalGreg BrockmanSarah FriarScott SchoolsFormerMira MuratiEmmett ShearBoard ofdirectorsCurrentSam AltmanAdam D'AngeloSue Desmond-HellmannPaul NakasoneAdebayo OgunlesiNicole SeligmanFidji SimoLawrence SummersBret Taylor (chair)Jakub Pachocki (chief scientist)FormerGreg Brockman (2017\u20132023)Reid Hoffman (2019\u20132023)Will Hurd (2021\u20132023)Holden Karnofsky (2017\u20132021)Elon Musk (2015\u20132018)Ilya Sutskever (2017\u20132023)Helen Toner (2021\u20132023)Shivon Zilis (2019\u20132023)Joint venturesStargate LLCRelatedApple IntelligenceAI DungeonAutoGPT\"Deep Learning\"LangChainMicrosoft CopilotOpenAI FiveTransformerCategoryvteDifferentiable computingGeneralDifferentiable programmingInformation geometryStatistical manifoldAutomatic differentiationNeuromorphic computingPattern recognitionRicci calculusComputational learning theoryInductive biasHardwareIPUTPUVPUMemristorSpiNNakerSoftware librariesTensorFlowPyTorchKerasscikit-learnTheanoJAXFlux.jlMindSpore Portals\nComputer programmingTechnology\n\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=LangChain&oldid=1284159477\"", "tags": ["en.wikipedia.org", "wiki", "langchain"]}
